{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from typing import Callable, Any\n",
    "\n",
    "from record_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LOAD_UTIL_CONFIG.LOAD_UTIL = True\n",
    "load_all_play_records()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def get_time_series_func(extract_item: Callable[[AssignmentStatistics], Any],\n",
    "                         scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    scheduler_to_items = defaultdict(list)\n",
    "    scheduler_to_curr_record_idx = defaultdict(int)\n",
    "    time_interval *= 1e9\n",
    "    time_interval = int(time_interval)\n",
    "    for i in count(0):\n",
    "        now = i * time_interval\n",
    "        has_none_zero = False\n",
    "        for scheduler, record in scheduler_to_record.items():\n",
    "            idx = scheduler_to_curr_record_idx[scheduler]\n",
    "            while idx + 1 < len(record.assignment_statistics) and record.assignment_statistics[idx + 1].now < now:\n",
    "                idx += 1\n",
    "            if idx >= len(record.assignment_statistics) - 1:\n",
    "                # break\n",
    "                # scheduler_to_items[scheduler].append(0)\n",
    "                continue\n",
    "            has_none_zero = True\n",
    "            scheduler_to_curr_record_idx[scheduler] = idx\n",
    "            assignment_stats = record.assignment_statistics[idx]\n",
    "            item = extract_item(assignment_stats)\n",
    "            scheduler_to_items[scheduler].append(item)\n",
    "        if not has_none_zero:\n",
    "            break\n",
    "    return scheduler_to_items\n",
    "\n",
    "\n",
    "def time_series_profit(scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    return get_time_series_func(lambda assignment_stats: assignment_stats.profit, scheduler_to_record,\n",
    "                                time_interval)\n",
    "\n",
    "\n",
    "def time_series_comp_util(scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    return get_time_series_func(lambda assignment_stats: assignment_stats.total_comp_util, scheduler_to_record,\n",
    "                                time_interval)\n",
    "\n",
    "\n",
    "def time_series_mem_util(scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    return get_time_series_func(lambda assignment_stats: assignment_stats.total_mem_utilization, scheduler_to_record,\n",
    "                                time_interval)\n",
    "\n",
    "\n",
    "def time_series_deployed_count(scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    return get_time_series_func(lambda assignment_stats: assignment_stats.deployed_job_size, scheduler_to_record,\n",
    "                                time_interval)\n",
    "\n",
    "\n",
    "def plot_avg_time_series_profit_bar():\n",
    "    original_fontsize = mpl.rcParams[\"font.size\"]\n",
    "    mpl.rcParams.update({'font.size': 24})\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.Kubernetes,\n",
    "                  SchedulerName.AFS,\n",
    "                  SchedulerName.SPREAD_PRIME]\n",
    "    fig, ax = plt.subplots(figsize=(16, 4))\n",
    "    data_source_names = [\n",
    "        DataSourceName.DataSourceAliDyn,\n",
    "        DataSourceName.DataSourceAliSta,\n",
    "        DataSourceName.DataSourcePhiDyn,\n",
    "        DataSourceName.DataSourcePhiSta,\n",
    "    ]\n",
    "    X = np.arange(len(data_source_names))\n",
    "    width = 0.1\n",
    "    schedulers_to_avg_profits = defaultdict(list)\n",
    "    for i, data_source_name in enumerate(data_source_names):\n",
    "        scheduler_to_record = dict()\n",
    "        for scheduler in schedulers:\n",
    "            play_record = extract_play_record(mode=SessionMode.Trace,\n",
    "                                              data_source_name=data_source_name,\n",
    "                                              cluster_name=ClusterName.Cluster64,\n",
    "                                              scheduler_name=scheduler)\n",
    "            assert len(play_record) == 1\n",
    "            play_record = play_record[0]\n",
    "            scheduler_to_record[scheduler] = play_record\n",
    "        scheduler_to_profits = time_series_profit(scheduler_to_record)\n",
    "        for scheduler in schedulers:\n",
    "            profits = scheduler_to_profits[scheduler]\n",
    "            profits = list(filter(lambda profit: profit > 64, profits))\n",
    "            schedulers_to_avg_profits[scheduler].append(np.mean(profits))\n",
    "\n",
    "    hatch = \"/\"\n",
    "    for i, scheduler in enumerate(schedulers):\n",
    "        avg_profits = schedulers_to_avg_profits[scheduler]\n",
    "        spec = scheduler_to_spec(scheduler_name=scheduler)\n",
    "        print(f\"{scheduler}: \", np.array(avg_profits))\n",
    "        ax.bar(\n",
    "            X + i * width,\n",
    "            np.array(avg_profits),\n",
    "            # edgecolor=edgecolor,\n",
    "            width=width,\n",
    "            color=spec[\"color\"],\n",
    "            label=spec[\"label\"],\n",
    "            hatch=hatch\n",
    "        )\n",
    "    ax.set_xticks(X + (width / 2) * (len(schedulers) - 1),\n",
    "                  [data_source_to_spec(data_source_name=dn)[\"label\"] for dn in data_source_names])\n",
    "    # ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "    y_major_loc = plt_ticker.MultipleLocator(base=30)\n",
    "    ax.yaxis.set_major_locator(y_major_loc)\n",
    "    fig.tight_layout()\n",
    "    fig.legend(loc=(0.1, 0.68), ncol=4)\n",
    "    fig.subplots_adjust(top=0.6)\n",
    "    ax.set_ylabel('Avg. $\\hat{T}$')\n",
    "    ax.set_xlabel('Workloads')\n",
    "    ax.yaxis.grid(True)\n",
    "    save_fig(fig, output_path(f\"avg_profit_bar.pdf\"))\n",
    "    mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "def plot_makespan_bar():\n",
    "    original_fontsize = mpl.rcParams[\"font.size\"]\n",
    "    mpl.rcParams.update({'font.size': 26})\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.AFS,\n",
    "                  SchedulerName.Kubernetes,\n",
    "                  SchedulerName.SPREAD_PRIME]\n",
    "    cluster_name = ClusterName.Cluster64\n",
    "    fig, ax = plt.subplots(figsize=(16, 4))\n",
    "    data_source_names = [\n",
    "        DataSourceName.DataSourceAliSta,\n",
    "        DataSourceName.DataSourcePhiSta,\n",
    "    ]\n",
    "    X = np.arange(len(data_source_names))\n",
    "    width = 0.1\n",
    "    schedulers_to_makespans = defaultdict(list)\n",
    "    for i, data_source_name in enumerate(data_source_names):\n",
    "        for scheduler in schedulers:\n",
    "            play_record = extract_play_record(\n",
    "                mode=SessionMode.Trace,\n",
    "                data_source_name=data_source_name,\n",
    "                cluster_name=cluster_name,\n",
    "                scheduler_name=scheduler)\n",
    "            assert len(play_record) == 1\n",
    "            play_record = play_record[0]\n",
    "            max_completion_time = np.max([done_job.completion_time for done_job in play_record.done_records.values()])\n",
    "            schedulers_to_makespans[scheduler].append(max_completion_time)\n",
    "\n",
    "    bottom = 0.75\n",
    "    hatch = \"/\"\n",
    "    for i, scheduler in enumerate(schedulers):\n",
    "        base = schedulers_to_makespans[SchedulerName.SPREAD]\n",
    "        makespans = schedulers_to_makespans[scheduler]\n",
    "        makespans_normalized = np.array(makespans) / np.array(base)\n",
    "        spec = scheduler_to_spec(scheduler_name=scheduler)\n",
    "        print(f\"{scheduler}: \", np.array(makespans_normalized))\n",
    "        ax.bar(\n",
    "            X + i * width,\n",
    "            np.array(makespans_normalized) - bottom,\n",
    "            width=width,\n",
    "            color=spec[\"color\"],\n",
    "            label=spec[\"label\"],\n",
    "            hatch=hatch,\n",
    "            bottom=bottom\n",
    "        )\n",
    "    ax.spines['bottom'].set_position(('data', bottom))\n",
    "    ax.set_xticks(X + (width / 2) * (len(schedulers) - 1),\n",
    "                  [data_source_to_spec(data_source_name=dn)[\"label\"] for dn in data_source_names])\n",
    "    ax.set_yticks([1, 1.25, 1.5, 1.75])\n",
    "    fig.tight_layout()\n",
    "    fig.legend(loc=(0.1, 0.68), ncol=4)\n",
    "    fig.subplots_adjust(top=0.6)\n",
    "    ax.set_ylabel('Norm. Makespan')\n",
    "    ax.set_xlabel('Workloads')\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "    save_fig(fig, output_path(f\"makespan_bar.pdf\"))\n",
    "    mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "def plot_JCT_bar():\n",
    "    original_fontsize = mpl.rcParams[\"font.size\"]\n",
    "    mpl.rcParams.update({'font.size': 26})\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.AFS,\n",
    "                  # SchedulerName.Kubernetes,\n",
    "                  SchedulerName.SPREAD_PRIME]\n",
    "    fig, ax = plt.subplots(figsize=(16, 4))\n",
    "    cluster_name = ClusterName.Cluster64\n",
    "    data_source_names = [\n",
    "        DataSourceName.DataSourceAliDyn,\n",
    "        DataSourceName.DataSourceAliSta,\n",
    "        DataSourceName.DataSourcePhiDyn,\n",
    "        DataSourceName.DataSourcePhiSta,\n",
    "    ]\n",
    "    X = np.arange(len(data_source_names))\n",
    "    width = 0.1\n",
    "    schedulers_to_JCTs = defaultdict(list)\n",
    "    for i, data_source_name in enumerate(data_source_names):\n",
    "        for scheduler in schedulers:\n",
    "            play_record = extract_play_record(\n",
    "                mode=SessionMode.Trace,\n",
    "                data_source_name=data_source_name,\n",
    "                cluster_name=cluster_name,\n",
    "                scheduler_name=scheduler)\n",
    "            assert len(play_record) == 1\n",
    "            play_record = play_record[0]\n",
    "            JCTs = list()\n",
    "            for done_job in play_record.done_records.values():\n",
    "                JCT = done_job.completion_time - done_job.submit_time\n",
    "                JCTs.append(JCT)\n",
    "            avg_jct = np.mean(JCTs)\n",
    "            schedulers_to_JCTs[scheduler].append(avg_jct)\n",
    "\n",
    "    bottom = 0.75\n",
    "    hatch = \"/\"\n",
    "    for i, scheduler in enumerate(schedulers):\n",
    "        base = schedulers_to_JCTs[SchedulerName.SPREAD]\n",
    "        avgJCTs = schedulers_to_JCTs[scheduler]\n",
    "        avgJCTs_normalized = np.array(avgJCTs) / np.array(base)\n",
    "        spec = scheduler_to_spec(scheduler_name=scheduler)\n",
    "        print(f\"{scheduler}: \", np.array(avgJCTs_normalized))\n",
    "        ax.bar(\n",
    "            X + i * width,\n",
    "            np.array(avgJCTs_normalized) - bottom,\n",
    "            width=width,\n",
    "            color=spec[\"color\"],\n",
    "            label=spec[\"label\"],\n",
    "            hatch=hatch,\n",
    "            bottom=bottom\n",
    "        )\n",
    "    ax.spines['bottom'].set_position(('data', bottom))\n",
    "    ax.set_xticks(X + (width / 2) * (len(schedulers) - 1),\n",
    "                  [data_source_to_spec(data_source_name=dn)[\"label\"] for dn in data_source_names])\n",
    "    ax.set_yticks([1, 1.5, 2.0])\n",
    "    fig.tight_layout()\n",
    "    fig.legend(loc=(0.1, 0.68), ncol=3)\n",
    "    fig.subplots_adjust(top=0.6)\n",
    "    ax.set_ylabel('Norm. $JCT_{avg}$')\n",
    "    ax.set_xlabel('Workloads')\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "    save_fig(fig, output_path(f\"JCT_bar.pdf\"))\n",
    "    mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "def plot_JCT_and_makespan_bar():\n",
    "    # original_fontsize = mpl.rcParams[\"font.size\"]\n",
    "    mpl.rcParams.update({'font.size': 26})\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5), gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "    def plot_JCT(ax):\n",
    "        schedulers = [SchedulerName.SPREAD,\n",
    "                      SchedulerName.KubeShare,\n",
    "                      SchedulerName.Gavel,\n",
    "                      SchedulerName.Hydra,\n",
    "                      SchedulerName.AFS,\n",
    "                      # SchedulerName.Kubernetes,\n",
    "                      SchedulerName.SPREAD_PRIME]\n",
    "        cluster_name = ClusterName.Cluster64\n",
    "        data_source_names = [\n",
    "            DataSourceName.DataSourceAliDyn,\n",
    "            DataSourceName.DataSourceAliSta,\n",
    "            DataSourceName.DataSourcePhiDyn,\n",
    "            DataSourceName.DataSourcePhiSta,\n",
    "        ]\n",
    "        X = np.arange(len(data_source_names))\n",
    "        width = 0.1\n",
    "        schedulers_to_JCTs = defaultdict(list)\n",
    "        for i, data_source_name in enumerate(data_source_names):\n",
    "            for scheduler in schedulers:\n",
    "                play_record = extract_play_record(\n",
    "                    mode=SessionMode.Trace,\n",
    "                    data_source_name=data_source_name,\n",
    "                    cluster_name=cluster_name,\n",
    "                    scheduler_name=scheduler)\n",
    "                assert len(play_record) == 1\n",
    "                play_record = play_record[0]\n",
    "                JCTs = list()\n",
    "                for done_job in play_record.done_records.values():\n",
    "                    JCT = done_job.completion_time - done_job.submit_time\n",
    "                    JCTs.append(JCT)\n",
    "                avg_jct = np.mean(JCTs)\n",
    "                schedulers_to_JCTs[scheduler].append(avg_jct)\n",
    "\n",
    "        bottom = 0.75\n",
    "        hatch = \"/\"\n",
    "        for i, scheduler in enumerate(schedulers):\n",
    "            base = schedulers_to_JCTs[SchedulerName.SPREAD]\n",
    "            avgJCTs = schedulers_to_JCTs[scheduler]\n",
    "            avgJCTs_normalized = np.array(avgJCTs) / np.array(base)\n",
    "            spec = scheduler_to_spec(scheduler_name=scheduler)\n",
    "            print(f\"{scheduler} avg JCT for each workloads: \", np.array(avgJCTs_normalized))\n",
    "            ax.bar(\n",
    "                X + i * width,\n",
    "                np.array(avgJCTs_normalized) - bottom,\n",
    "                width=width,\n",
    "                color=spec[\"color\"],\n",
    "                label=spec[\"label\"],\n",
    "                hatch=hatch,\n",
    "                bottom=bottom\n",
    "            )\n",
    "        ax.spines['bottom'].set_position(('data', bottom))\n",
    "        ax.set_xticks(X + (width / 2) * (len(schedulers) - 1),\n",
    "                      [data_source_to_spec(data_source_name=dn)[\"label\"] for dn in data_source_names])\n",
    "        ax.set_yticks([1, 1.5, 2.0])\n",
    "        ax.set_ylabel('Norm. $JCT_{avg}$')\n",
    "        ax.set_xlabel('Workloads')\n",
    "        ax.yaxis.grid(True)\n",
    "        ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "    def plot_makespan(ax):\n",
    "        schedulers = [SchedulerName.SPREAD,\n",
    "                      SchedulerName.KubeShare,\n",
    "                      SchedulerName.Gavel,\n",
    "                      SchedulerName.Hydra,\n",
    "                      SchedulerName.AFS,\n",
    "                      SchedulerName.Kubernetes,\n",
    "                      SchedulerName.SPREAD_PRIME]\n",
    "        cluster_name = ClusterName.Cluster64\n",
    "        data_source_names = [\n",
    "            DataSourceName.DataSourceAliSta,\n",
    "            DataSourceName.DataSourcePhiSta,\n",
    "        ]\n",
    "        X = np.arange(len(data_source_names))\n",
    "        width = 0.1\n",
    "        schedulers_to_makespans = defaultdict(list)\n",
    "        for i, data_source_name in enumerate(data_source_names):\n",
    "            for scheduler in schedulers:\n",
    "                play_record = extract_play_record(\n",
    "                    mode=SessionMode.Trace,\n",
    "                    data_source_name=data_source_name,\n",
    "                    cluster_name=cluster_name,\n",
    "                    scheduler_name=scheduler)\n",
    "                assert len(play_record) == 1\n",
    "                play_record = play_record[0]\n",
    "                max_completion_time = np.max(\n",
    "                    [done_job.completion_time for done_job in play_record.done_records.values()])\n",
    "                schedulers_to_makespans[scheduler].append(max_completion_time)\n",
    "\n",
    "        bottom = 0.75\n",
    "        hatch = \"/\"\n",
    "        for i, scheduler in enumerate(schedulers):\n",
    "            base = schedulers_to_makespans[SchedulerName.SPREAD]\n",
    "            makespans = schedulers_to_makespans[scheduler]\n",
    "            makespans_normalized = np.array(makespans) / np.array(base)\n",
    "            spec = scheduler_to_spec(scheduler_name=scheduler)\n",
    "            print(f\"{scheduler} makespan for each workloads: \", np.array(makespans_normalized))\n",
    "            ax.bar(\n",
    "                X + i * width,\n",
    "                np.array(makespans_normalized) - bottom,\n",
    "                width=width,\n",
    "                color=spec[\"color\"],\n",
    "                label=spec[\"label\"],\n",
    "                hatch=hatch,\n",
    "                bottom=bottom\n",
    "            )\n",
    "        ax.spines['bottom'].set_position(('data', bottom))\n",
    "        ax.set_xticks(X + (width / 2) * (len(schedulers) - 1),\n",
    "                      [data_source_to_spec(data_source_name=dn)[\"label\"] for dn in data_source_names])\n",
    "        ax.set_yticks([1, 1.25, 1.5, 1.75])\n",
    "        ax.set_ylabel('Norm. Makespan')\n",
    "        ax.set_xlabel('Workloads')\n",
    "        ax.yaxis.grid(True)\n",
    "        ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "\n",
    "    plot_JCT(axes[0])\n",
    "    plot_makespan(axes[1])\n",
    "    fig.tight_layout()\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.AFS,\n",
    "                  SchedulerName.Kubernetes,\n",
    "                  SchedulerName.SPREAD_PRIME]\n",
    "\n",
    "    handles = list()\n",
    "    for i, scheduler in enumerate(schedulers):\n",
    "        spec = scheduler_to_spec(scheduler_name=scheduler)\n",
    "        color = spec[\"color\"]\n",
    "        hatch = \"/\"\n",
    "        handle = Patch(\n",
    "            facecolor=color,\n",
    "            edgecolor=\"black\",\n",
    "            label=spec[\"label\"],\n",
    "            hatch=hatch\n",
    "        )\n",
    "        handles.append(handle)\n",
    "\n",
    "    fig.legend(handles=handles, loc=(0.02, 0.72), ncol=4, framealpha=0.3)\n",
    "    fig.subplots_adjust(top=0.65)\n",
    "    save_fig(fig, output_path(f\"JCT_makespan_bar.pdf\"))\n",
    "    # mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "def plot_time_series_item_for_record(ax, time_series_func, data_source_name: DataSourceName,\n",
    "                                     scheduler_to_record: Dict[SchedulerName, PlayRecord], y_label, max_item=16,\n",
    "                                     yticks=None):\n",
    "    scheduler_to_item = time_series_func(scheduler_to_record, time_interval=60)\n",
    "    time_point_count = max([len(item) for item in scheduler_to_item.values()])\n",
    "    # for scheduler, profits in scheduler_to_item.items():\n",
    "    #     assert len(profits) == time_point_count\n",
    "    X = np.arange(time_point_count)\n",
    "    inside_ticks(ax)\n",
    "    # y_major_loc = plt_ticker.MultipleLocator()\n",
    "    # ax.yaxis.set_major_locator(y_major_loc)\n",
    "    major_loc = 60 * 24\n",
    "    data_source_name_to_multiple_locator = {\n",
    "        DataSourceName.DataSourceAliDyn: 1 * major_loc,\n",
    "        DataSourceName.DataSourceAliSta: 1 * major_loc,\n",
    "        DataSourceName.DataSourcePhiDyn: 1 * major_loc,\n",
    "        DataSourceName.DataSourcePhiSta: 1 * major_loc\n",
    "    }\n",
    "    multiple_locator = data_source_name_to_multiple_locator[data_source_name]\n",
    "    x_major_loc = plt_ticker.MultipleLocator(base=multiple_locator)\n",
    "    x_minor_loc = plt_ticker.MultipleLocator(base=multiple_locator // 4)\n",
    "    ax.xaxis.set_major_locator(x_major_loc)\n",
    "    ax.xaxis.set_minor_locator(x_minor_loc)\n",
    "    ax.xaxis.set_major_formatter(plt_ticker.FuncFormatter(lambda v, pos: int(v / major_loc)))\n",
    "    if max_item is not None:\n",
    "        ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "    handles = []\n",
    "\n",
    "    phi_days = int(60 * 24 * 2.5)  # 2.5 days\n",
    "    ali_days = int(60 * 24 * 1.25)  # 1.25 days\n",
    "    time_limit = {\n",
    "        DataSourceName.DataSourceAliSta: ali_days,\n",
    "        DataSourceName.DataSourceAliDyn: ali_days,\n",
    "        DataSourceName.DataSourcePhiSta: phi_days,\n",
    "        DataSourceName.DataSourcePhiDyn: phi_days\n",
    "    }[data_source_name]\n",
    "    for scheduler_name, y_data in scheduler_to_item.items():\n",
    "        y_data = np.array(y_data)\n",
    "        if max_item is not None:\n",
    "            y_data = y_data.clip(max=max_item)\n",
    "            y_data = y_data / max_item\n",
    "        spec = scheduler_to_spec(scheduler_name)\n",
    "        label = spec[\"label\"]\n",
    "        zorder = spec[\"zorder\"]\n",
    "        linestyle = spec[\"linestyle\"]\n",
    "        linewidth = 3\n",
    "        color = spec[\"color\"]\n",
    "        X = np.arange(len(y_data))\n",
    "        if len(X) > time_limit:\n",
    "            X = X[:time_limit]\n",
    "            y_data = y_data[:time_limit]\n",
    "        ax.plot(X, y_data,\n",
    "                marker=None,\n",
    "                linestyle=linestyle,\n",
    "                linewidth=linewidth,\n",
    "                label=label,\n",
    "                zorder=zorder,\n",
    "                color=color,\n",
    "                )\n",
    "        handle = mlines.Line2D(\n",
    "            [], [],\n",
    "            color=color,\n",
    "            marker=None,\n",
    "            linestyle=linestyle,\n",
    "            label=label,\n",
    "            zorder=zorder,\n",
    "            linewidth=linewidth,\n",
    "        )\n",
    "        handles.append(handle)\n",
    "    if yticks is not None:\n",
    "        ax.set_yticks(yticks)\n",
    "        # ax.set_yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xlabel('Time (Day)')\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_title(f\"{data_source_to_spec(data_source_name)['label']}\")\n",
    "    return handles\n",
    "\n",
    "\n",
    "def plot_time_series_item_for_all_records(time_series_func, cluster_name, filename, max_item, y_label, yticks=None):\n",
    "    original_fontsize = mpl.rcParams[\"font.size\"]\n",
    "    mpl.rcParams.update({'font.size': 24})\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.AFS,\n",
    "                  SchedulerName.Kubernetes,\n",
    "                  SchedulerName.SPREAD_PRIME]\n",
    "    data_source_names = [\n",
    "        DataSourceName.DataSourceAliDyn,\n",
    "        DataSourceName.DataSourceAliSta,\n",
    "        DataSourceName.DataSourcePhiDyn,\n",
    "        DataSourceName.DataSourcePhiSta,\n",
    "    ]\n",
    "    col = 2\n",
    "    fig, axes = plt.subplots(2, col, figsize=(16, 9))\n",
    "    handles = None\n",
    "    for i, data_source_name in enumerate(data_source_names):\n",
    "        scheduler_to_record = dict()\n",
    "        for scheduler in schedulers:\n",
    "            play_record = extract_play_record(mode=SessionMode.Trace,\n",
    "                                              data_source_name=data_source_name,\n",
    "                                              cluster_name=cluster_name,\n",
    "                                              scheduler_name=scheduler)\n",
    "            assert len(play_record) == 1\n",
    "            play_record = play_record[0]\n",
    "            scheduler_to_record[scheduler] = play_record\n",
    "        handles = plot_time_series_item_for_record(axes[i // col, i % col],\n",
    "                                                   time_series_func=time_series_func,\n",
    "                                                   data_source_name=data_source_name,\n",
    "                                                   scheduler_to_record=scheduler_to_record,\n",
    "                                                   max_item=max_item,\n",
    "                                                   y_label=y_label,\n",
    "                                                   yticks=yticks)\n",
    "    fig.tight_layout()\n",
    "    nrow = 2\n",
    "    lgd = fig.legend(handles=handles, loc=(0.05, 0.86), ncol=len(handles) // nrow + 1)\n",
    "    lgd.get_frame().set_alpha(None)\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "    save_fig(fig, output_path(filename))\n",
    "    mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "def plot_time_series_items_for_all_records():\n",
    "    plot_time_series_item_for_all_records(time_series_func=time_series_profit, cluster_name=ClusterName.Cluster64,\n",
    "                                          filename=\"time_series_throughput.pdf\", y_label=r\"$\\hat{T}_{total}$\",\n",
    "                                          max_item=None, yticks=[0, 30, 60])\n",
    "    # plot_time_series_item_for_all_records(time_series_func=time_series_mem_util, cluster_name=ClusterName.Cluster10GPUs,\n",
    "    #                                       filename=\"time_series_10GPUs_mem.pdf\", y_label=\"Memory Utilization\",\n",
    "    #                                       max_item=1)\n",
    "    plot_time_series_item_for_all_records(time_series_func=time_series_comp_util,\n",
    "                                          cluster_name=ClusterName.Cluster64,\n",
    "                                          filename=\"time_series_utilization.pdf\", y_label=\"GPU Utilization\",\n",
    "                                          max_item=64 * 100)\n",
    "    # plot_time_series_item_for_all_records(time_series_func=time_series_deployed_count,\n",
    "    #                                       cluster_name=ClusterName.Cluster64,\n",
    "    #                                       filename=\"time_series_placed_job_size.pdf\", y_label=\"Placed Job Size\",\n",
    "    #                                       max_item=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if LOAD_UTIL_CONFIG.LOAD_UTIL:\n",
    "    plot_time_series_items_for_all_records()\n",
    "    # plot_avg_time_series_profit_bar()\n",
    "# plot_makespan_bar()\n",
    "# plot_JCT_bar()\n",
    "plot_JCT_and_makespan_bar()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
