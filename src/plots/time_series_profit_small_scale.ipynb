{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from typing import Callable, Any\n",
    "\n",
    "from record_preprocess import *\n",
    "\n",
    "cluster_to_color = {\n",
    "    ClusterName.Cluster8: colors[0],\n",
    "    ClusterName.Cluster8R: colors[1]\n",
    "}\n",
    "\n",
    "cluster_to_label = {\n",
    "    ClusterName.Cluster8: \"Simulator\",\n",
    "    ClusterName.Cluster8R: \"Ground Truth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LOAD_UTIL_CONFIG.LOAD_UTIL = True\n",
    "load_all_play_records(cluster_name_set={ClusterName.Cluster8, ClusterName.Cluster8R})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def get_time_series_func(extract_item: Callable[[AssignmentStatistics], Any],\n",
    "                         scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    scheduler_to_items = defaultdict(list)\n",
    "    scheduler_to_curr_record_idx = defaultdict(int)\n",
    "    time_interval *= 1e9\n",
    "    time_interval = int(time_interval)\n",
    "    for i in count(0):\n",
    "        now = i * time_interval\n",
    "        has_none_zero = False\n",
    "        for scheduler, record in scheduler_to_record.items():\n",
    "            idx = scheduler_to_curr_record_idx[scheduler]\n",
    "            while idx + 1 < len(record.assignment_statistics) and record.assignment_statistics[idx + 1].now < now:\n",
    "                idx += 1\n",
    "            if idx >= len(record.assignment_statistics) - 1:\n",
    "                # break\n",
    "                # scheduler_to_items[scheduler].append(0)\n",
    "                continue\n",
    "            has_none_zero = True\n",
    "            scheduler_to_curr_record_idx[scheduler] = idx\n",
    "            assignment_stats = record.assignment_statistics[idx]\n",
    "            item = extract_item(assignment_stats)\n",
    "            scheduler_to_items[scheduler].append(item)\n",
    "        if not has_none_zero:\n",
    "            break\n",
    "    return scheduler_to_items\n",
    "\n",
    "\n",
    "def time_series_profit(scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    return get_time_series_func(lambda assignment_stats: 2 * assignment_stats.profit, scheduler_to_record,\n",
    "                                time_interval)\n",
    "\n",
    "\n",
    "def time_series_comp_util(scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    return get_time_series_func(lambda assignment_stats: assignment_stats.total_comp_util, scheduler_to_record,\n",
    "                                time_interval)\n",
    "\n",
    "\n",
    "def time_series_mem_util(scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    return get_time_series_func(lambda assignment_stats: assignment_stats.total_mem_utilization, scheduler_to_record,\n",
    "                                time_interval)\n",
    "\n",
    "\n",
    "def time_series_deployed_count(scheduler_to_record: Dict[SchedulerName, PlayRecord], time_interval=60):\n",
    "    return get_time_series_func(lambda assignment_stats: assignment_stats.deployed_job_size, scheduler_to_record,\n",
    "                                time_interval)\n",
    "\n",
    "\n",
    "def plot_avg_time_series_profit_bar(ax):\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.AFS,\n",
    "                  SchedulerName.Kubernetes,\n",
    "                  ]\n",
    "    data_source_name = DataSourceName.DataSourcePhiSta\n",
    "    cluster_names = [ClusterName.Cluster8, ClusterName.Cluster8R]\n",
    "    X = np.arange(len(schedulers))\n",
    "    width = 0.3\n",
    "    cluster_to_avg_profits = defaultdict(list)\n",
    "    for i, cluster_name in enumerate(cluster_names):\n",
    "        scheduler_to_record = dict()\n",
    "        for scheduler in schedulers:\n",
    "            play_record = extract_play_record(mode=SessionMode.Trace,\n",
    "                                              data_source_name=data_source_name,\n",
    "                                              cluster_name=cluster_name,\n",
    "                                              scheduler_name=scheduler)\n",
    "            assert len(play_record) == 1\n",
    "            play_record = play_record[0]\n",
    "            scheduler_to_record[scheduler] = play_record\n",
    "        scheduler_to_profits = time_series_profit(scheduler_to_record)\n",
    "        for scheduler in schedulers:\n",
    "            profits = scheduler_to_profits[scheduler]\n",
    "            profits = list(filter(lambda profit: profit > 4, profits))\n",
    "            cluster_to_avg_profits[cluster_name].append(np.mean(profits))\n",
    "\n",
    "    hatch = \"/\"\n",
    "    for i, cluster_name in enumerate(cluster_names):\n",
    "        avg_profits = cluster_to_avg_profits[cluster_name]\n",
    "        print(f\"{cluster_name}: \", np.array(avg_profits))\n",
    "        ax.bar(\n",
    "            X + i * width,\n",
    "            np.array(avg_profits),\n",
    "            # edgecolor=edgecolor,\n",
    "            width=width,\n",
    "            color=cluster_to_color[cluster_name],\n",
    "            label=cluster_to_label[cluster_name],\n",
    "            hatch=hatch\n",
    "        )\n",
    "    ax.set_xticks(X + (width / 2),\n",
    "                  [scheduler_to_spec(scheduler_name=s)[\"label\"] for s in schedulers], rotation=35)\n",
    "    # ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "    y_major_loc = plt_ticker.MultipleLocator(base=5)\n",
    "    ax.yaxis.set_major_locator(y_major_loc)\n",
    "    ax.set_ylabel('Avg. $\\hat{T}_{total}$')\n",
    "    # ax.set_xlabel('Workloads')\n",
    "    # fig.tight_layout()\n",
    "    # fig.legend(loc=(0.1, 0.68), ncol=4)\n",
    "    # fig.subplots_adjust(top=0.6)\n",
    "    ax.yaxis.grid(True)\n",
    "    # save_fig(fig, output_path(f\"avg_profit_bar.pdf\"))\n",
    "    # mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "def plot_avg_time_series_util_bar(ax):\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.AFS,\n",
    "                  SchedulerName.Kubernetes,\n",
    "                  ]\n",
    "    data_source_name = DataSourceName.DataSourcePhiSta\n",
    "    cluster_names = [ClusterName.Cluster8, ClusterName.Cluster8R]\n",
    "    X = np.arange(len(schedulers))\n",
    "    width = 0.3\n",
    "    cluster_to_avg_utils = defaultdict(list)\n",
    "    for i, cluster_name in enumerate(cluster_names):\n",
    "        scheduler_to_record = dict()\n",
    "        for scheduler in schedulers:\n",
    "            play_record = extract_play_record(mode=SessionMode.Trace,\n",
    "                                              data_source_name=data_source_name,\n",
    "                                              cluster_name=cluster_name,\n",
    "                                              scheduler_name=scheduler)\n",
    "            assert len(play_record) == 1\n",
    "            play_record = play_record[0]\n",
    "            scheduler_to_record[scheduler] = play_record\n",
    "        scheduler_to_utils = time_series_comp_util(scheduler_to_record)\n",
    "        for scheduler in schedulers:\n",
    "            utils = scheduler_to_utils[scheduler]\n",
    "            utils = list(filter(lambda u: u > 400, utils))\n",
    "            cluster_to_avg_utils[cluster_name].append(np.mean(utils) / 800)\n",
    "\n",
    "    hatch = \"/\"\n",
    "    for i, cluster_name in enumerate(cluster_names):\n",
    "        avg_utils = cluster_to_avg_utils[cluster_name]\n",
    "        print(f\"{cluster_name}: \", np.array(avg_utils))\n",
    "        ax.bar(\n",
    "            X + i * width,\n",
    "            np.array(avg_utils),\n",
    "            # edgecolor=edgecolor,\n",
    "            width=width,\n",
    "            color=cluster_to_color[cluster_name],\n",
    "            label=cluster_to_label[cluster_name],\n",
    "            hatch=hatch\n",
    "        )\n",
    "    ax.set_xticks(X + (width / 2),\n",
    "                  [scheduler_to_spec(scheduler_name=s)[\"label\"] for s in schedulers], rotation=35)\n",
    "    ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "    y_major_loc = plt_ticker.MultipleLocator(base=0.5)\n",
    "    ax.yaxis.set_major_locator(y_major_loc)\n",
    "    ax.set_ylabel('Avg. GPU Util.')\n",
    "    # ax.set_xlabel('Workloads')\n",
    "    # fig.tight_layout()\n",
    "    # fig.legend(loc=(0.1, 0.68), ncol=4)\n",
    "    # fig.subplots_adjust(top=0.6)\n",
    "    ax.yaxis.grid(True)\n",
    "    # save_fig(fig, output_path(f\"avg_profit_bar.pdf\"))\n",
    "    # mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "def plot_makespan_bar(ax):\n",
    "    # original_fontsize = mpl.rcParams[\"font.size\"]\n",
    "    # mpl.rcParams.update({'font.size': 26})\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.AFS,\n",
    "                  SchedulerName.Kubernetes,\n",
    "                  ]\n",
    "    data_source_name = DataSourceName.DataSourcePhiSta\n",
    "    cluster_names = [ClusterName.Cluster8, ClusterName.Cluster8R]\n",
    "    X = np.arange(len(schedulers))\n",
    "    width = 0.3\n",
    "    cluster_to_makespans = defaultdict(list)\n",
    "    base = int(1e16)\n",
    "    for i, cluster_name in enumerate(cluster_names):\n",
    "        for scheduler in schedulers:\n",
    "            play_record = extract_play_record(\n",
    "                mode=SessionMode.Trace,\n",
    "                data_source_name=data_source_name,\n",
    "                cluster_name=cluster_name,\n",
    "                scheduler_name=scheduler)\n",
    "            assert len(play_record) == 1\n",
    "            play_record = play_record[0]\n",
    "            max_completion_time = np.max([done_job.completion_time for done_job in play_record.done_records.values()])\n",
    "            cluster_to_makespans[cluster_name].append(max_completion_time)\n",
    "            base = min(base, max_completion_time)\n",
    "\n",
    "    bottom = 0.75\n",
    "    hatch = \"/\"\n",
    "    for i, cluster_name in enumerate(cluster_names):\n",
    "        makespans = cluster_to_makespans[cluster_name]\n",
    "        makespans_normalized = np.array(makespans) / np.array(base)\n",
    "        print(f\"{cluster_name}: \", np.array(makespans_normalized))\n",
    "        ax.bar(\n",
    "            X + i * width,\n",
    "            np.array(makespans_normalized) - bottom,\n",
    "            width=width,\n",
    "            color=cluster_to_color[cluster_name],\n",
    "            label=cluster_to_label[cluster_name],\n",
    "            hatch=hatch,\n",
    "            bottom=bottom\n",
    "        )\n",
    "    ax.spines['bottom'].set_position(('data', bottom))\n",
    "    ax.set_xticks(X + (width / 2),\n",
    "                  [scheduler_to_spec(s)[\"label\"] for s in schedulers], rotation=35)\n",
    "    ax.set_yticks([1, 1.25, 1.5, 1.75])\n",
    "    # fig.tight_layout()\n",
    "    # fig.legend(loc=(0.1, 0.68), ncol=4)\n",
    "    # fig.subplots_adjust(top=0.6)\n",
    "    ax.set_ylabel('Norm. Makespan')\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "    # save_fig(fig, output_path(f\"makespan_bar.pdf\"))\n",
    "    # mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "def plot_JCT_bar(ax):\n",
    "    # original_fontsize = mpl.rcParams[\"font.size\"]\n",
    "    # mpl.rcParams.update({'font.size': 26})\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.AFS,\n",
    "                  SchedulerName.Kubernetes,\n",
    "                  ]\n",
    "    # fig, ax = plt.subplots(figsize=(16, 4))\n",
    "    cluster_names = [ClusterName.Cluster8, ClusterName.Cluster8R]\n",
    "    data_source_name = DataSourceName.DataSourcePhiSta\n",
    "    X = np.arange(len(schedulers))\n",
    "    width = 0.3\n",
    "    cluster_to_JCTs = defaultdict(list)\n",
    "    base = int(1e16)\n",
    "    for i, cluster_name in enumerate(cluster_names):\n",
    "        for scheduler in schedulers:\n",
    "            play_record = extract_play_record(\n",
    "                mode=SessionMode.Trace,\n",
    "                data_source_name=data_source_name,\n",
    "                cluster_name=cluster_name,\n",
    "                scheduler_name=scheduler)\n",
    "            assert len(play_record) == 1\n",
    "            play_record = play_record[0]\n",
    "            JCTs = list()\n",
    "            for done_job in play_record.done_records.values():\n",
    "                JCT = done_job.completion_time - done_job.submit_time\n",
    "                JCTs.append(JCT)\n",
    "            avg_jct = np.mean(JCTs)\n",
    "            cluster_to_JCTs[cluster_name].append(avg_jct)\n",
    "            base = min(base, avg_jct)\n",
    "\n",
    "    bottom = 0.75\n",
    "    hatch = \"/\"\n",
    "    for i, cluster_name in enumerate(cluster_names):\n",
    "        avgJCTs = cluster_to_JCTs[cluster_name]\n",
    "        avgJCTs_normalized = np.array(avgJCTs) / np.array(base)\n",
    "        print(f\"{cluster_name}: \", np.array(avgJCTs_normalized))\n",
    "        ax.bar(\n",
    "            X + i * width,\n",
    "            np.array(avgJCTs_normalized) - bottom,\n",
    "            width=width,\n",
    "            color=cluster_to_color[cluster_name],\n",
    "            label=cluster_to_label[cluster_name],\n",
    "            hatch=hatch,\n",
    "            bottom=bottom\n",
    "        )\n",
    "    ax.spines['bottom'].set_position(('data', bottom))\n",
    "    ax.set_xticks(X + (width / 2),\n",
    "                  [scheduler_to_spec(s)[\"label\"] for s in schedulers], rotation=35)\n",
    "    ax.set_yticks([1, 1.5, 2.0])\n",
    "    # fig.tight_layout()\n",
    "    # fig.legend(loc=(0.1, 0.68), ncol=3)\n",
    "    # fig.subplots_adjust(top=0.6)\n",
    "    ax.set_ylabel('Norm. $JCT_{avg}$')\n",
    "    # ax.set_xlabel('Workloads')\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "    # save_fig(fig, output_path(f\"JCT_bar.pdf\"))\n",
    "    # mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "def plot_time_series_item_for_record(ax, time_series_func, data_source_name: DataSourceName,\n",
    "                                     scheduler_to_record: Dict[SchedulerName, PlayRecord], y_label, max_item=16,\n",
    "                                     yticks=None):\n",
    "    scheduler_to_item = time_series_func(scheduler_to_record, time_interval=60)\n",
    "    time_point_count = max([len(item) for item in scheduler_to_item.values()])\n",
    "    # for scheduler, profits in scheduler_to_item.items():\n",
    "    #     assert len(profits) == time_point_count\n",
    "    X = np.arange(time_point_count)\n",
    "    inside_ticks(ax)\n",
    "    # y_major_loc = plt_ticker.MultipleLocator()\n",
    "    # ax.yaxis.set_major_locator(y_major_loc)\n",
    "    major_loc = 60 * 24\n",
    "    data_source_name_to_multiple_locator = {\n",
    "        DataSourceName.DataSourcePhiSta: 1 * major_loc,\n",
    "        DataSourceName.DataSourcePhiSta: 1 * major_loc,\n",
    "        DataSourceName.DataSourcePhiDyn: 1 * major_loc,\n",
    "        DataSourceName.DataSourcePhiSta: 1 * major_loc\n",
    "    }\n",
    "    multiple_locator = data_source_name_to_multiple_locator[data_source_name]\n",
    "    x_major_loc = plt_ticker.MultipleLocator(base=multiple_locator)\n",
    "    x_minor_loc = plt_ticker.MultipleLocator(base=multiple_locator // 4)\n",
    "    ax.xaxis.set_major_locator(x_major_loc)\n",
    "    ax.xaxis.set_minor_locator(x_minor_loc)\n",
    "    ax.xaxis.set_major_formatter(plt_ticker.FuncFormatter(lambda v, pos: int(v / major_loc)))\n",
    "    if max_item is not None:\n",
    "        ax.yaxis.set_major_formatter(plt_ticker.FuncFormatter('{0:.0%}'.format))\n",
    "    handles = []\n",
    "\n",
    "    phi_days = int(60 * 24 * 2.5)  # 2.5 days\n",
    "    ali_days = int(60 * 24 * 1.25)  # 1.25 days\n",
    "    time_limit = {\n",
    "        DataSourceName.DataSourcePhiSta: ali_days,\n",
    "        DataSourceName.DataSourcePhiSta: ali_days,\n",
    "        DataSourceName.DataSourcePhiSta: phi_days,\n",
    "        DataSourceName.DataSourcePhiDyn: phi_days\n",
    "    }[data_source_name]\n",
    "    for scheduler_name, y_data in scheduler_to_item.items():\n",
    "        y_data = np.array(y_data)\n",
    "        if max_item is not None:\n",
    "            y_data = y_data.clip(max=max_item)\n",
    "            y_data = y_data / max_item\n",
    "        spec = scheduler_to_spec(scheduler_name)\n",
    "        label = spec[\"label\"]\n",
    "        zorder = spec[\"zorder\"]\n",
    "        linestyle = spec[\"linestyle\"]\n",
    "        linewidth = 5\n",
    "        color = spec[\"color\"]\n",
    "        X = np.arange(len(y_data))\n",
    "        if len(X) > time_limit:\n",
    "            X = X[:time_limit]\n",
    "            y_data = y_data[:time_limit]\n",
    "        ax.plot(X, y_data,\n",
    "                marker=None,\n",
    "                linestyle=linestyle,\n",
    "                linewidth=linewidth,\n",
    "                label=label,\n",
    "                zorder=zorder,\n",
    "                color=color,\n",
    "                )\n",
    "        handle = mlines.Line2D(\n",
    "            [], [],\n",
    "            color=color,\n",
    "            marker=None,\n",
    "            linestyle=linestyle,\n",
    "            label=label,\n",
    "            zorder=zorder,\n",
    "            linewidth=linewidth,\n",
    "        )\n",
    "        handles.append(handle)\n",
    "    if yticks is not None:\n",
    "        ax.set_yticks(yticks)\n",
    "        # ax.set_yticks([0, 0.25, 0.5, 0.75, 1])\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xlabel('Time (Day)')\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_title(f\"{data_source_to_spec(data_source_name)['label']}\")\n",
    "    return handles\n",
    "\n",
    "\n",
    "def plot_time_series_item_for_all_records(time_series_func, cluster_name, filename, max_item, y_label, yticks=None):\n",
    "    original_fontsize = mpl.rcParams[\"font.size\"]\n",
    "    mpl.rcParams.update({'font.size': 24})\n",
    "    schedulers = [SchedulerName.SPREAD,\n",
    "                  SchedulerName.KubeShare,\n",
    "                  SchedulerName.Gavel,\n",
    "                  SchedulerName.Hydra,\n",
    "                  SchedulerName.AFS,\n",
    "                  SchedulerName.Kubernetes,\n",
    "                  SchedulerName.SPREAD_PRIME]\n",
    "    data_source_names = [\n",
    "        DataSourceName.DataSourcePhiSta,\n",
    "        DataSourceName.DataSourcePhiSta,\n",
    "        DataSourceName.DataSourcePhiDyn,\n",
    "        DataSourceName.DataSourcePhiSta,\n",
    "    ]\n",
    "    col = 2\n",
    "    fig, axes = plt.subplots(2, col, figsize=(16, 9))\n",
    "    handles = None\n",
    "    for i, data_source_name in enumerate(data_source_names):\n",
    "        scheduler_to_record = dict()\n",
    "        for scheduler in schedulers:\n",
    "            play_record = extract_play_record(mode=SessionMode.Trace,\n",
    "                                              data_source_name=data_source_name,\n",
    "                                              cluster_name=cluster_name,\n",
    "                                              scheduler_name=scheduler)\n",
    "            assert len(play_record) == 1\n",
    "            play_record = play_record[0]\n",
    "            scheduler_to_record[scheduler] = play_record\n",
    "        handles = plot_time_series_item_for_record(axes[i // col, i % col],\n",
    "                                                   time_series_func=time_series_func,\n",
    "                                                   data_source_name=data_source_name,\n",
    "                                                   scheduler_to_record=scheduler_to_record,\n",
    "                                                   max_item=max_item,\n",
    "                                                   y_label=y_label,\n",
    "                                                   yticks=yticks)\n",
    "    fig.tight_layout()\n",
    "    nrow = 2\n",
    "    lgd = fig.legend(handles=handles, loc=(0.05, 0.86), ncol=len(handles) // nrow + 1)\n",
    "    lgd.get_frame().set_alpha(None)\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "    save_fig(fig, output_path(filename))\n",
    "    mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "def plot_time_series_items_for_all_records():\n",
    "    plot_time_series_item_for_all_records(time_series_func=time_series_profit, cluster_name=ClusterName.Cluster64,\n",
    "                                          filename=\"time_series_profits.pdf\", y_label=r\"$\\hat{T}_{total}$\",\n",
    "                                          max_item=None, yticks=[0, 30, 60, 90, 120])\n",
    "    # plot_time_series_item_for_all_records(time_series_func=time_series_mem_util, cluster_name=ClusterName.Cluster10GPUs,\n",
    "    #                                       filename=\"time_series_10GPUs_mem.pdf\", y_label=\"Memory Utilization\",\n",
    "    #                                       max_item=1)\n",
    "    plot_time_series_item_for_all_records(time_series_func=time_series_comp_util,\n",
    "                                          cluster_name=ClusterName.Cluster64,\n",
    "                                          filename=\"time_series_comp.pdf\", y_label=\"GPU Utilization\",\n",
    "                                          max_item=64 * 100)\n",
    "    # plot_time_series_item_for_all_records(time_series_func=time_series_deployed_count,\n",
    "    #                                       cluster_name=ClusterName.Cluster64,\n",
    "    #                                       filename=\"time_series_placed_job_size.pdf\", y_label=\"Placed Job Size\",\n",
    "    #                                       max_item=None)\n",
    "def create_verification():\n",
    "    original_fontsize = mpl.rcParams[\"font.size\"]\n",
    "    mpl.rcParams.update({'font.size': 26})\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 7))\n",
    "    plot_avg_time_series_profit_bar(axes[0, 0])\n",
    "    plot_avg_time_series_util_bar(axes[0, 1])\n",
    "    plot_makespan_bar(axes[1, 0])\n",
    "    plot_JCT_bar(axes[1, 1])\n",
    "\n",
    "    handles = list()\n",
    "\n",
    "    for i, cluster_name in enumerate([ClusterName.Cluster8, ClusterName.Cluster8R]):\n",
    "        hatch = \"/\"\n",
    "        handle = Patch(\n",
    "            facecolor=cluster_to_color[cluster_name],\n",
    "            edgecolor=\"black\",\n",
    "            label=cluster_to_label[cluster_name],\n",
    "            hatch=hatch\n",
    "        )\n",
    "        handles.append(handle)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    nrow = 2\n",
    "    lgd = fig.legend(handles=handles, loc=(0.07, 0.88), ncol=len(handles) // nrow + 1)\n",
    "    lgd.get_frame().set_alpha(None)\n",
    "    fig.subplots_adjust(top=0.86)\n",
    "    save_fig(fig, output_path(f\"simulator_validation.pdf\"))\n",
    "    mpl.rcParams.update({'font.size': original_fontsize})\n",
    "\n",
    "\n",
    "\n",
    "create_verification()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
